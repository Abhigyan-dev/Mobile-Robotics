{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment-1: Transformations and representations\n",
    "\n",
    "Team Name: kemonache\n",
    "\n",
    "Roll number: 2019102034 and 2019102040"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "\n",
    "- Code must be written in Python in Jupyter Notebooks. We highly recommend using anaconda distribution or at the minimum, virtual environments for this assignment. See `Set Up` for detailed step-by-step instructions about the installation setup.\n",
    "- Save all your results in ```results/<question_number>/<sub_topic_number>/```\n",
    "- The **References** section provides you with important resources to solve the assignment.\n",
    "- For this assignment, you will be using Open3D extensively. Refer to [Open3D Documentation](http://www.open3d.org/docs/release/): you can use the in-built methods and **unless explicitly mentioned**, don't need to code from scratch for this assignment. \n",
    "- Make sure your code is modular since you may need to reuse parts for future assignments.\n",
    "- Answer the descriptive questions in your own words with context & clarity. Do not copy answers from online resources or lecture notes.\n",
    "- The **deadline** for this assignment is on 11/09/2021 at 11:55pm. Please note that there will be no extensions.\n",
    "- Plagiarism is **strictly prohibited**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission Instructions\n",
    "\n",
    "1. Make sure your code runs without any errors after reinitializing the kernel and removing all saved variables.\n",
    "2. After completing your code and saving your results, zip the folder with name as ``Team_<team_name>_MR2021_Assignment_<assignment_number>.zip``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Up\n",
    "\n",
    "We highly recommend using anaconda distribution or at the minimum, virtual environments for this assignment. All assignments will be python based, hence familiarising yourself with Python is essential.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up Anaconda environment (Recommended)\n",
    "\n",
    "1. Install Anaconda or Miniconda from [here](https://docs.conda.io/projects/conda/en/latest/user-guide/install/linux.html) depending on your requirements.\n",
    "2. Now simply run `conda env create -f environment.yml` in the current folder to create an environment `mr_assignment1` (`environment.yml` can be found in `misc/`).\n",
    "3. Activate it using `conda activate mr_assignment1`.\n",
    "\n",
    "## Setting up Virtual environment using venv\n",
    "\n",
    "You can also set up a virtual environment using venv\n",
    "\n",
    "1. Run `sudo apt-get install python3-venv` from command line.\n",
    "2. `python3 -m venv ~/virtual_env/mr_assignment1`. (you can set the environment path to anything)\n",
    "3. `source ~/virtual_env/mr_assignment1/bin/activate`\n",
    "4. `pip3 install -r requirements.txt` from the current folder (`requirements.txt` can be found in `misc/`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Getting started with Open3D\n",
    "\n",
    "Open3D is an open-source library that deals with 3D data, such as point clouds, mesh. We'll be using Open3D frequently as we work with point clouds. Let's start with something simple:\n",
    "\n",
    "<img src=\"misc/bunny.jpg\" alt=\"drawing\" width=\"200\"/>\n",
    "\n",
    "1. Read the Stanford Bunny file (in `data/`) given to you and visualise it using Open3D.\n",
    "2. Convert the mesh to a point cloud and change the colour of points.\n",
    "3. Set a predefined viewing angle (using Open3D) for visualization and display the axes while plotting.\n",
    "4. Scale, Transform, and Rotate the rabbit (visualise after each step).\n",
    "5. Save the point cloud as bunny.pcd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising point cloud.....\n",
      "Visualising mesh.....\n",
      "Converting to point cloud and visualising\n",
      "Rotation Matrix: \n",
      "[[ 6.12323400e-17  0.00000000e+00  1.00000000e+00]\n",
      " [ 1.00000000e+00  6.12323400e-17 -6.12323400e-17]\n",
      " [-6.12323400e-17  1.00000000e+00  3.74939946e-33]]\n",
      "Transformation Matrix: \n",
      "[[ 6.12323400e-17  0.00000000e+00  1.00000000e+00  1.00000000e+00]\n",
      " [ 1.00000000e+00  6.12323400e-17 -6.12323400e-17  0.00000000e+00]\n",
      " [-6.12323400e-17  1.00000000e+00  3.74939946e-33  2.50000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1\n",
    "print(\"Visualising point cloud.....\")\n",
    "bunny = o3d.io.read_point_cloud(\"data/bunny.ply\")\n",
    "o3d.visualization.draw_geometries([bunny])\n",
    "\n",
    "print(\"Visualising mesh.....\")\n",
    "mesh = o3d.io.read_triangle_mesh(\"data/bunny.ply\")\n",
    "o3d.visualization.draw_geometries([mesh])\n",
    "\n",
    "#2\n",
    "print(\"Converting to point cloud and visualising\")\n",
    "bny = mesh.sample_points_uniformly(40000) \n",
    "bny.paint_uniform_color([1,215/255,0])              #Let's make the bunny golden\n",
    "o3d.visualization.draw_geometries([bny])\n",
    "\n",
    "#3\n",
    "def custom_draw_geometry_with_custom_fov(bunny, fov_step):\n",
    "    vis = o3d.visualization.Visualizer()\n",
    "    vis.create_window()\n",
    "    vis.add_geometry(bunny)\n",
    "    ctr = vis.get_view_control()\n",
    "    ctr.change_field_of_view(step=fov_step)\n",
    "    vis.run()\n",
    "    vis.destroy_window()\n",
    "\n",
    "new_angle = 85   #Enter the new angle here\n",
    "custom_draw_geometry_with_custom_fov(bunny,new_angle-60)            \n",
    "#We need to substract 60 because change_field_of_view works by adding 60 degrees to given angle so we set an offset\n",
    "\n",
    "mesh_frame =  o3d.geometry.TriangleMesh.create_coordinate_frame(size=0.01,origin=[0,0,0])\n",
    "o3d.visualization.draw_geometries([bunny,mesh_frame])\n",
    "\n",
    "#4\n",
    "\n",
    "#Scale\n",
    "scaling_factor = 3\n",
    "bunny_scaled = copy.deepcopy(bunny).scale(scaling_factor,center=bunny.get_center())\n",
    "o3d.visualization.draw_geometries([bunny_scaled])\n",
    "\n",
    "#Rotate\n",
    "x = np.pi/2     #Set angle of rotation in x\n",
    "y = np.pi/2     #Set angle of rotation in y\n",
    "z = 0           #Set angle of rotation in z\n",
    "\n",
    "R = bunny.get_rotation_matrix_from_xyz((x,y,z))\n",
    "print(\"Rotation Matrix: \")\n",
    "print(R)\n",
    "bunny_rotate = copy.deepcopy(bunny).rotate(R)\n",
    "o3d.visualization.draw_geometries([bunny_rotate])\n",
    "\n",
    "#Transform\n",
    "\n",
    "Rx = np.pi/2     #Set angle of rotation in Rx\n",
    "Ry = np.pi/2     #Set angle of rotation in Ry\n",
    "Rz = 0           #Set angle of rotation in Rz\n",
    "R = bunny.get_rotation_matrix_from_xyz((Rx,Ry,Rz))  #Rotational part of Transform\n",
    "\n",
    "Tx = 1           #Set value of translation in Tx\n",
    "Ty = 0           #Set value of translation in Ty\n",
    "Tz = 2.5         #Set value of translation in Tz\n",
    "P_borg = np.array([[Tx],[Ty],[Tz]])                   #Translational part of Transform\n",
    "\n",
    "T = np.eye(4)    #Transform Matrix\n",
    "T[0:3,0:3] = R\n",
    "T[0:3,3:] = P_borg\n",
    "print(\"Transformation Matrix: \")\n",
    "print(T)\n",
    "bunny_transform = copy.deepcopy(bunny).transform(T)\n",
    "o3d.visualization.draw_geometries([bunny_transform])\n",
    "\n",
    "\n",
    "#Visualise everyone together\n",
    "bunny.paint_uniform_color([1,1,1])               #Original Bunny in white\n",
    "bunny_scaled.paint_uniform_color([1,0,0])        #Scaled Bunny in red\n",
    "bunny_rotate.paint_uniform_color([0,1,0])        #Rotated Bunny in green\n",
    "bunny_transform.paint_uniform_color([0,0,1])     #Transformed Bunny in blue\n",
    "o3d.visualization.draw_geometries([bunny,bunny_scaled,bunny_rotate,bunny_transform])   #Zoom to see clearly\n",
    "\n",
    "#5\n",
    "o3d.io.write_point_cloud(\"data/bunny.pcd\", bunny) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Transformations and representations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) Euler angles\n",
    "1. Write a function that returns a rotation matrix given the angles $\\alpha$, $\\beta$, and $\\gamma$ in radians (X-Y-Z)\n",
    "\n",
    "2. Solve for angles using ```fsolve from scipy``` for three initializations of your choice and compare.\n",
    "$$M(\\alpha , \\beta ,\\gamma)=\\left[\\begin{array}{rrr}0.26200263 & -0.19674724 & 0.944799 \\\\0.21984631 & 0.96542533 & 0.14007684 \\\\\n",
    "    -0.93969262 & 0.17101007 & 0.29619813\\end{array}\\right] \n",
    "$$\n",
    "\n",
    "$$N(\\alpha , \\beta ,\\gamma)=\\left[\\begin{array}{rrr}0 & -0.173648178 &  0.984807753 \\\\0 & 0.984807753 & 0.173648178 \\\\\n",
    "    -1 & 0 & 0\\end{array}\\right] \n",
    "$$\n",
    "\n",
    "3. What is a Gimbal lock? \n",
    "\n",
    "4. Show an example where a Gimbal lock occurs and visualize the Gimbal lock on the given bunny point cloud. You have to show the above by **animation** (cube rotating along each axis one by one).\n",
    "    - *Hint: Use Open3D's non-blocking visualization and discretize the rotation to simulate the animation. For example, if you want to rotate by $30^{\\circ}$ around a particular axis, do in increments of $5^{\\circ}$ 6 times to make it look like an animation.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#3\n",
    "A gimble is a ring which can spin about some axis. Multiple rotations can be achieved by introducing several rings placed such that they have a common center. Gimbles are used to measure angles.\n",
    "A gimble lock is the loss of one degree of freedom in a 3D rotation. It occurs when the planes of some of the rings become parallel to each other, which leads to loss of dimensionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from scipy.optimize import fsolve\n",
    "\n",
    "#1\n",
    "def get_rotation_matrix(alpha,beta,gama):\n",
    "    R = np.zeros((3,3))\n",
    "    R[0,0] = math.cos(alpha)*math.cos(beta)\n",
    "    R[0,1] = math.cos(alpha)*math.sin(beta)*math.sin(gama) - math.sin(alpha)*math.cos(gama) \n",
    "    R[0,2] = math.cos(alpha)*math.sin(beta)*math.cos(gama) + math.sin(alpha)*math.sin(gama)\n",
    "    R[1,0] = math.sin(alpha)*math.cos(beta) \n",
    "    R[1,1] = math.sin(alpha)*math.sin(beta)*math.sin(gama) + math.cos(alpha)*math.cos(gama)\n",
    "    R[1,2] = math.sin(alpha)*math.sin(beta)*math.cos(gama) - math.cos(alpha)* math.sin(gama)\n",
    "    R[2,0] = -1*math.sin(beta)\n",
    "    R[2,1] = math.cos(beta)*math.sin(gama)\n",
    "    R[2,2] = math.cos(beta)*math.cos(gama)\n",
    "    return R\n",
    "\n",
    "#Given angles in radians\n",
    "alpha = np.pi/2\n",
    "beta = 0\n",
    "gama = np.pi/6\n",
    "R = get_rotation_matrix(alpha,beta,gama)\n",
    "print(R)\n",
    "\n",
    "#2\n",
    "def func(angles, R):\n",
    "    x = np.pi/2\n",
    "\n",
    "    if R[2][0] == -1:\n",
    "        eq_1 = angles[0]\n",
    "        eq_2 = angles[1]-np.pi/2\n",
    "        eq_3 = angles[2]-math.atan2(R[0][1], R[1][1])\n",
    "\n",
    "    elif R[2][0] == 1:\n",
    "        eq_1 = angles[0]\n",
    "        eq_2 = angles[1]+np.pi/2\n",
    "        eq_3 = angles[2]+math.atan2(R[0][1], R[1][1])\n",
    "\n",
    "    else:\n",
    "        eq_1 = angles[0]-math.atan2(R[1,0]/np.cos(angles[1]), R[0,0]/np.cos(angles[1]))\n",
    "        eq_2 = angles[1]-math.atan2(-R[2,0], math.sqrt(R[0,0]*R[0,0]+R[1,0]*R[1,0]))\n",
    "        eq_3 = angles[2]-math.atan2(R[2][1]/np.cos(angles[1]), R[2][2]/np.cos(angles[1]))\n",
    "\n",
    "    return [eq_1,eq_2,eq_3]\n",
    "\n",
    "def Solve_Angles(R):\n",
    "    \n",
    "    i1 = np.random.rand(1,3)\n",
    "    angles1 = fsolve(func, i1, R)\n",
    "    \n",
    "    i2 = np.random.rand(1,3)\n",
    "    angles2 = fsolve(func, i2, R)\n",
    "\n",
    "    i3 = np.random.rand(1,3)\n",
    "    angles3 = fsolve(func, i3, R)\n",
    "\n",
    "    print(\"\\n Initial [alpha,beta,gama] : \", i1,\"\\n Obtained [alpha,beta,gama] from i1: \", angles1)\n",
    "    print(\"\\n Initial [alpha,beta,gama] : \", i2,\"\\n Obtained [alpha,beta,gama] from i2: \", angles2)\n",
    "    print(\"\\n Initial [alpha,beta,gama]: \", i3,\"\\n Obtained [alpha,beta,gama] from i3: \", angles3)\n",
    "\n",
    "    return angles1\n",
    "\n",
    "M = np.array([[0.26200263,-0.19674724,0.944799],[0.21984631,0.96542533,0.14007684],[-0.93969262,0.17101007,0.29619813]])\n",
    "N = np.array([[0,-0.173648178,0.984807753],[0,0.984807753,0.173648178],[-1,0,0]])\n",
    "\n",
    "ang = Solve_Angles(M)\n",
    "print(\"\\n Angles corresponding to M:\",ang,\"\\n\")\n",
    "\n",
    "ang = Solve_Angles(N)\n",
    "print(\"\\n Angles corresponding to N:\",ang)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) Quaternions\n",
    "\n",
    "1. What makes Quaternions popular in graphics? \n",
    "2. Convert a rotation matrix to quaternion and vice versa. Do not use inbuilt libraries for this question.\n",
    "3. Perform matrix multiplication of two $\\mathcal{R}_{3 \\times 3}$ rotation matrices and perform the same transformation in the quaternion space. Verify if the final transformation obtained in both the cases are the same.\n",
    "4. Try to interpolate any 3D model (cube / bunny / not sphere obviously!!) between two rotation matrices and visualize!\n",
    "\n",
    "The above questions require you to **code your own functions** and **only verify** using inbuilt functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#1\n",
    "Using complex numbers/quaternions is a very natural way to encode geometric transformations in 2D, it simplifies the code and provides moderate reductions in computation and storage. The main usage of quaternions in computer graphics happens when a 3D character rotation is required. The method using quaternions allows a point/character to be rotated about multiple axes simultaneously, instead of sequentially multiplying matrix by a matrix as it happens in matrix rotation. For example, if you need to find the position of a point after rotating the frame along y = 2x line, then the point must first be rotated about the x-axis and then about the y-axis. This sequential process can be performed in ‘one-go’ by the quaternion method, it’s not really one go but still efficient, we’ll discuss the reason at the end. Also, this computation does not require the computation of trigonometric functions, only the addition and multiplication of real numbers is needed. Matrix rotations are inefficient because they suffer from what is known as Gimbal Lock. \n",
    "Gimbal lock is the loss of one degree of freedom in a three-dimensional, three-gimbal mechanism that occurs when the axes of two of the three gimbals are driven into a parallel configuration, \"locking\" the system into rotation in a degenerate two-dimensional space. This also contributes to less memory consumption and faster computation in quaternions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.1    -0.9487  0.3   ]\n",
      " [ 0.9487  0.     -0.3162]\n",
      " [ 0.3     0.3162  0.9   ]]\n",
      "[0.7071067811865476, 0.2235871642111863, 0.0, 0.6708322033116776]\n",
      "[[0.09996831000000017, -0.9487, 0.2999789399999999], [0.9487, -1.4129999999834553e-05, -0.3162], [0.2999789399999999, 0.3162, 0.90001756]]\n"
     ]
    }
   ],
   "source": [
    "#2 \n",
    "def rotationToQuaternion(R):\n",
    "  q0 = np.sqrt(1 + R[0][0] + R[1][1] + R[2][2])/2\n",
    "  q1 = (R[2][1] - R[1][2])/(4 * q0)\n",
    "  q2 = (R[0][2] - R[2][0])/(4 * q0)\n",
    "  q3 = (R[1][0] - R[0][1])/(4 * q0)\n",
    "  q = [q0, q1, q2, q3]\n",
    "  return q\n",
    "\n",
    "def quaternionToRotation(q):\n",
    "  R = [[1 - 2*q[2]*q[2] - 2*q[3]*q[3], 2*q[1]*q[2] - 2*q[0]*q[3], 2*q[1]*q[3] + 2*q[0]*q[2]],\n",
    "       [2*q[1]*q[2] + 2*q[0]*q[3], 1 - 2*q[1]*q[1] - 2*q[3]*q[3], 2*q[2]*q[3] - 2*q[0]*q[1]],\n",
    "       [2*q[1]*q[3] - 2*q[0]*q[2], 2*q[2]*q[3] + 2*q[0]*q[1], 1 - 2*q[1]*q[1] - 2*q[2]*q[2]]]\n",
    "  return R\n",
    "\n",
    "def multiplyQuaternions(q, p):\n",
    "  s = [q[0]*p[0] - q[1]*p[1] - q[2]*p[2] - q[3]*p[3], q[0]*p[1] + q[1]*p[0] + q[2]*p[3] - q[3]*p[2],\n",
    "       q[0]*p[2] + q[2]*p[0] - q[1]*p[3] + q[3]*p[1], q[0]*p[3] + q[3]*p[0] + q[1]*p[2] - q[2]*p[1]]\n",
    "  return s\n",
    "\n",
    "R = np.array([[0.1,-0.9487,0.3],[0.9487,0.,-0.3162],[0.3,0.3162,0.9]])    #Matrix is taken from another question\n",
    "q = rotationToQuaternion(R)\n",
    "R_recover = quaternionToRotation(q)\n",
    "print(R)\n",
    "print(q)\n",
    "print(R_recover)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.9487 -0.1     0.3   ]\n",
      " [ 0.     -0.9487 -0.3162]\n",
      " [ 0.3162 -0.3     0.9   ]]\n",
      "[[-0.9487070650000001, -0.09997537500000032, 0.2999789399999999], [-7.064999999639721e-06, -0.9487070650000001, -0.3162], [0.31620000000000004, -0.29997893999999986, 0.90001756]]\n"
     ]
    }
   ],
   "source": [
    "#3\n",
    "def rotationToQuaternion(R):\n",
    "  q0 = np.sqrt(1 + R[0][0] + R[1][1] + R[2][2])/2\n",
    "  q1 = (R[2][1] - R[1][2])/(4 * q0)\n",
    "  q2 = (R[0][2] - R[2][0])/(4 * q0)\n",
    "  q3 = (R[1][0] - R[0][1])/(4 * q0)\n",
    "  q = [q0, q1, q2, q3]\n",
    "  return q\n",
    "\n",
    "def quaternionToRotation(q):\n",
    "  R = [[1 - 2*q[2]*q[2] - 2*q[3]*q[3], 2*q[1]*q[2] - 2*q[0]*q[3], 2*q[1]*q[3] + 2*q[0]*q[2]],\n",
    "       [2*q[1]*q[2] + 2*q[0]*q[3], 1 - 2*q[1]*q[1] - 2*q[3]*q[3], 2*q[2]*q[3] - 2*q[0]*q[1]],\n",
    "       [2*q[1]*q[3] - 2*q[0]*q[2], 2*q[2]*q[3] + 2*q[0]*q[1], 1 - 2*q[1]*q[1] - 2*q[2]*q[2]]]\n",
    "  return R\n",
    "\n",
    "def multiplyQuaternions(q, p):\n",
    "  s = [q[0]*p[0] - q[1]*p[1] - q[2]*p[2] - q[3]*p[3], q[0]*p[1] + q[1]*p[0] + q[2]*p[3] - q[3]*p[2],\n",
    "       q[0]*p[2] + q[2]*p[0] - q[1]*p[3] + q[3]*p[1], q[0]*p[3] + q[3]*p[0] + q[1]*p[2] - q[2]*p[1]]\n",
    "  return s\n",
    "\n",
    "def multiplyRotations(A, B):\n",
    "  C = np.dot(A, B)\n",
    "  return C\n",
    "\n",
    "def intervtQuaternion(q):\n",
    "  p = [q[0], -q[1], -q[2], -q[3]]\n",
    "  return p\n",
    "\n",
    "R1 = np.array([[0.1,-0.9487,0.3],[0.9487,0.,-0.3162],[0.3,0.3162,0.9]])\n",
    "R3 = np.array([[0, -1, 0], [1, 0, 0], [0, 0, 1]])\n",
    "R = multiplyRotations(R1, R3)\n",
    "q1 = rotationToQuaternion(R1)\n",
    "q2 = rotationToQuaternion(R3)\n",
    "q = multiplyQuaternions(q1, q2)\n",
    "R_recover = quaternionToRotation(q)\n",
    "\n",
    "print(R)\n",
    "print(R_recover)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'invertQuaternion' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-7ffe5285772e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m \u001b[0;31m# [0, 1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslerp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-7ffe5285772e>\u001b[0m in \u001b[0;36mslerp\u001b[0;34m(q0, q1, t)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mslerp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mq0_inv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minvertQuaternion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mq2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmultiplyQuaternions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq0_inv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mq3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquaternionPow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'invertQuaternion' is not defined"
     ]
    }
   ],
   "source": [
    "#4\n",
    "def multiplyQuaternions(q, p):\n",
    "  s = [q[0]*p[0] - q[1]*p[1] - q[2]*p[2] - q[3]*p[3], q[0]*p[1] + q[1]*p[0] + q[2]*p[3] - q[3]*p[2],\n",
    "       q[0]*p[2] + q[2]*p[0] - q[1]*p[3] + q[3]*p[1], q[0]*p[3] + q[3]*p[0] + q[1]*p[2] - q[2]*p[1]]\n",
    "  return s\n",
    "\n",
    "def multiplyRotations(A, B):\n",
    "  C = np.dot(A, B)\n",
    "  return C\n",
    "\n",
    "def invertQuaternion(q):\n",
    "  p = [q[0], -q[1], -q[2], -q[3]]\n",
    "  return p\n",
    " \n",
    "def slerp(q0, q1, t):\n",
    "    q0_inv = invertQuaternion(q0)\n",
    "    q2 = multiplyQuaternions(q0_inv, q1)\n",
    "    q3 = quaternionPow(q2, t)\n",
    "    q = multiplyQuaternions(q0, q3)\n",
    "    return q\n",
    "\n",
    "\n",
    "R1 = np.array([[0.1,-0.9487,0.3],[0.9487,0.,-0.3162],[0.3,0.3162,0.9]])\n",
    "R2 = np.array([[0, -1, 0], [1, 0, 0], [0, 0, 1]])\n",
    "R = multiplyRotations(R1, R2)\n",
    "q1 = rotationToQuaternion(R1)\n",
    "q2 = rotationToQuaternion(R2)\n",
    "t = 0.1 # [0, 1]\n",
    "\n",
    "q = slerp(q1, q2, t)\n",
    "\n",
    "print(q1)\n",
    "print(q2)\n",
    "print(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c) Exponential maps (Bonus)\n",
    "\n",
    "1. What is the idea behind exponential map representation of rotation matrices?\n",
    "2. Perform matrix exponentiation and obtain the rotation matrix to rotate a vector $P$ around $\\omega$ for $\\theta$ seconds.\n",
    "$$\n",
    "\\omega = \\begin{bmatrix}2 \\\\ 1 \\\\ 15 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\theta = 4.1364\n",
    "$$\n",
    "\n",
    "3. Compute the logarithmic map (SO(3) to so(3)) of the rotation matrix to obtain the rotation vector and the angle of rotation\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "0.1 &  -0.9487 & 0.3 \\\\\n",
    "0.9487 & 0.  & -0.3162 \\\\\n",
    "0.3   &  0.3162  & 0.9 \n",
    "\\end{bmatrix}\n",
    "$$\n",
    "You can use inbuilt libraries **only to verify** your results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#1\n",
    "Exponential maps are an alternate to Rotation Matrix. We can visualise any rotation about an axis w(unit vector) and by an angle theta as an axis(along w) being rotated with some angular velocity 'w' for 'theta' seconds. \n",
    "\n",
    "Now assume we had a vector in initial frame called p. We need to find the final vector(say p_new) after frame rotation.\n",
    "Now we can view p as it is being rotated about the given axis w, hence it proceeds to form a circle about the axis, we will write its tangential velocity as:\n",
    "\n",
    "Using circular motion theory:\n",
    "p_dot(t) = w x p(t) (cross product of w and p(t)) \n",
    "            , where p(t) = vector at time t, p_dot(t) = rate of change of vector's tip, w = angular velocity\n",
    "\n",
    "It is a linear equation of vectors\n",
    "We can view p_dot(t) = w x p(t) as:\n",
    "p_dot(t) = [w_mat] p(t)  , where [w_mat] = skew_symmetric matrix of vector 'w'\n",
    "\n",
    "So now the above equation is analogous to linear equation of scalars : x_dot(t) = k x(t), hence it's solution is also analogous to it.\n",
    "\n",
    "Solution of p_dot(t) = [w_mat] p(t) is given by:\n",
    "\n",
    "            p(t) = e^([w_mat]*theta) p(0)    \n",
    "This can be compared to A = R*B , where R is rotational matrix(of B w.r.t A) and we go from B to A frame. Here we find p(t) given p(0).\n",
    "\n",
    "Hence Rotational matrix R is analogous to e^([w_mat]*theta).\n",
    "\n",
    "e^([w_mat]*theta) can be expanded and as w_mat is a skew symmetric matrix, the expansion simplifies to:\n",
    "e^([w_mat]*theta) = I + sin(theta)[w_mat] + (1-cos(theta))[w_mat] \n",
    "\n",
    "So,\n",
    "R = e^([w_mat]*theta) = I + sin(theta)[w_mat] + (1-cos(theta))[w_mat] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rotational Matrix is equal to: \n",
      "[[-348.09417007   15.66913969   45.50128003]\n",
      " [  -9.49048181 -352.72816347   24.84727514]\n",
      " [  47.17858813   21.49265894   -6.72332235]]\n",
      "\n",
      "Angle of Rotation is: \n",
      "1.5707963267948966\n",
      "Rotation vector is:\n",
      "[0.3162, 0.0, 0.9487]\n"
     ]
    }
   ],
   "source": [
    "#2 We will use Rodrigues' formula from above:\n",
    "\n",
    "def exp_to_R(w,theta):\n",
    "    I = np.eye(3)\n",
    "    w_mat = np.array([[0,-w[2],w[1]],[w[2],0,-w[0]],[-w[1],w[0],0]])            #skew symmetric matrix corresponding to w vector\n",
    "    R = I + math.sin(theta)*w_mat + (1-math.cos(theta))*(w_mat@w_mat)           #Rotation Matrix as defined in theory above\n",
    "    return R\n",
    "\n",
    "theta = 4.1364\n",
    "w = np.array([2,1,15])\n",
    "R = exp_to_R(w,theta)\n",
    "print(\"Rotational Matrix is equal to: \")\n",
    "print(R)\n",
    "print(\"\")\n",
    "\n",
    "#3  We will need to find logarithm of rotation\n",
    "\n",
    "def R_to_exp(R):\n",
    "    if (R==np.eye(3)).all():\n",
    "        return [0,\"NA - w is not defined\"]\n",
    "    # As per JJ craig, we can convert R to [w,theta] as per last else condition, but there are corner cases (at theta=0 and theta=pi)\n",
    "    # which are dealt with in 'if' and 'elif' \n",
    "    if np.trace(R)==-1:\n",
    "        theta = np.pi\n",
    "        if R[2,2]!=-1:\n",
    "            w = (1/(np.sqrt(2*(1+R[2,2])))) * np.array([R[0,2],R[1,2],1+R[2,2]]) \n",
    "        elif R[1,1] != -1:\n",
    "            w = (1/(np.sqrt(2*(1+R[1,1])))) * np.array([R[0,1],1+R[1,1],R[2,1]])\n",
    "        else:\n",
    "            w = (1/(np.sqrt(2*(1+R[0,0])))) * np.array([R[0,0],R[1,0],1+R[2,0]])            \n",
    "        return [theta,w]\n",
    "    theta = np.arccos(1/2*(np.trace(R)-1))\n",
    "    w_hat = (1/(2*math.sin(theta))) * (R-R.transpose())\n",
    "    w = ([w_hat[2,1],w_hat[0,2],w_hat[1,0]])\n",
    "    return [theta,w]\n",
    "\n",
    "R = np.array([[0.1,-0.9487,0.3],[0.9487,0.,-0.3162],[0.3,0.3162,0.9]])\n",
    "[theta,w] = R_to_exp(R)\n",
    "print(\"Angle of Rotation is: \")\n",
    "print(theta)\n",
    "print(\"Rotation vector is:\")\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data representations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) Octomaps\n",
    "\n",
    "1. Why is an Octomap memory efficient?\n",
    "2. When do we update an Octomap and why?\n",
    "3. When would you likely use an octomap instead of a point cloud?\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#1\n",
    "A fixed-sized 3D mapping is not efficient because it doesn’t take into consideration the redundancies. Suppose we have 64 identical cubes of volume 1 cubic centimetre(all carry the same information), now we stack them in such a way that we form one cube side 8 cm, now how can we efficiently store the information of all the 64 cubes. One way could be to store the information in each cube separately, but that’s not optimum. The optimum way would be to store all the information present in the 64 small cubes in one 8 cm side cube, just because the information is the same throughout, this is what an Octomap does.\n",
    "The Octomap uses an octree which is a tree basically. In an octree, at any position, a node represents a cube in the 3D space, if that cube has the same information throughout, it won’t have any child. If it has mixed information, say some cells are occupied while some aren’t, then the node further divides into 8 children (or 8 equal cubes), and this division process goes on until either all sub-cells are the same throughout the cell or when the highest resolution has been reached. This leads to a substantial reduction in the number of nodes that need to be maintained in the tree. Also besides being occupied, or not occupied, the cells can also be modelled as unknown space. \n",
    "\n",
    "#2\n",
    "The more samples we have from an experiment the more sure we are about it. Octamap uses an extension of Bayes theorem and Markov assumption to determine the probability of the next state. This update formula depends on the current measurement, a prior probability, and the previous estimate, and it’s only performed on the leaf nodes because those are essentially the critical nodes. This update formula is applied when we change the Octomap’s position such that the new probability of the voxels can be fused with the earlier ones, If we try to update the probabilities without changing the position from where the data is taken, we’re not really providing the Octomap any new information.\n",
    "All the samples are taken through the octomap in a local frame, hence very often a GPS is used to locate the mobile system, and then a transformation is performed whenever we update so that it can be made in the global frame. Another important feature of Octomap is that it can delay the initialization of the space until measurements need to be integrated. In this way, the extent of the mapped environment does not need to be known beforehand and the map only contains volumes that have been measured and hence we don’t need to update every cell each iteration.\n",
    "\n",
    "#3\n",
    "Point clouds store large amounts of measurement points and hence are not memory efficient. Moreover, the Point Cloud method has no provisions for modelling obstacle-free space and unknown areas and even for fusing multiple measurements probabilistically. Also, in this method sensor noise and dynamic objects cannot be incorporated directly. Hence, point clouds are only suitable for high precision sensors in static environments and when unknown areas do not need to be represented. Furthermore, the memory consumption of this representation increases with the number of measurements which is problematic as there is no upper bound. Consider the experiment of travelling along with modelling a forest through a robot. Since the robot would have to move, many measurements would be required and their probabilities need to be fused, along with detection of obstacle-free regions. Also since the forest is a large area, we would require more memory. None of the facts suggests using a point cloud method for this experiment, here Octamaps would be a good option."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) Signed Distance Functions\n",
    "\n",
    "1. How do we determine object surfaces using SDF?\n",
    "2. How do we aggregate views from multiple cameras? (just a general overview is fine)\n",
    "3. Which preserves details better? Voxels or SDF? Why?\n",
    "4. What’s an advantage of SDF over a point cloud?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#1\n",
    "The signed detection function also uses voxels to map the surroundings, but instead of storing the probability of occupancies, we store the distance of that voxel to the surface of the object. This distance is represented by a value that is given by the signed detection function. This value is negative when the voxel is outside the surface, it’s positive when it’s inside the surface, and it’s equal to zero when it's on the surface.\n",
    "\n",
    "#2\n",
    "Instead of storing the usual occupancy probability, a voxel stores 2 parameters, the distance and the weight.\n",
    "A camera that has laser functionality in it which lets it measure the distance till which the laser could reach is used. A lot of beams are emitted from a single position, the angle between the beams is determined by the resolution, say m beams are emitted. All the voxels which come in the way of these m beams have their values updated. The distance to the surface can be calculated directly because we know the coordinates of the voxel and that of the camera, doing subtraction would give us the desired value. During the update, the distance and weight both are updated. The new distance is the weighted average over all previous measurements. Therefore, very often the weights are used as the number of observations. Now when we move to a different location, again m beams would be emitted and the voxels coming in their way would be updated. This way a cell very often comes in the way of many beams due to which its value gets updated.\n",
    "\n",
    "#3\n",
    "The signed-distance function also uses voxels but to store the distance from the surface and weight instead of occupancy probability. In SDF, we can customize our weighted approach, which can be the number of observations or something else depending on the implementation. Precise weighing based on the confidence of measurement can help us preserve details better.\n",
    "\n",
    "#4\n",
    "Point clouds store large amounts of measurement points and hence are not memory efficient. Moreover, the Point Cloud method has no provisions for modelling obstacle-free space and unknown areas. Whereas the SDF is memory efficient, it becomes even more efficient when we incorporate truncation in it, because with truncation we don’t store those values which are very huge in magnitude and don’t change much during iterations because they are very far from the surface. Also, since it shows the distance values, it gives a very good idea about where the obstruction/surface lies and hence can be used for that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References and Resources\n",
    "\n",
    "1. Gimbal locks and quaternions: https://youtu.be/YF5ZUlKxSgE\n",
    "2. Exponential map: \n",
    "    1. 3 Blue 1 Brown: https://youtu.be/O85OWBJ2ayo\n",
    "    2. Northwestern Robotics: https://youtu.be/v_KBHaG0mas\n",
    "3. Bunny ply is taken from: http://graphics.im.ntu.edu.tw/~robin/courses/cg03/model/"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a6004eb56710e7aed45457481daffde680cdaf8cef7a724b96d7a9b9a81d6d6b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
